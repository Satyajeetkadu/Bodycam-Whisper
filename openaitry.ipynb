{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install cmake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install dlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import cv2\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode the image\n",
    "def encode_image(image):\n",
    "    _, buffer = cv2.imencode('.jpg', image)\n",
    "    return base64.b64encode(buffer).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"\"  # Replace with your OpenAI API key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_age_from_image(image):\n",
    "    # Encode the image\n",
    "    base64_image = encode_image(image)\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o\",\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": \"Predict the closest age of the person in this image and don't say you can't predict the age. Don't say if the age is in early or later age ranges, just give the exact age you think the person is in, don't even say that the person in the image is xyz years old, just give me the number only, I DONT WANT ANY OTHER OUTPUT , ONLY THE AGE IN NUMBER FORMAT!\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        age_prediction = response_data['choices'][0]['message']['content']\n",
    "        try:\n",
    "            age = int(age_prediction)\n",
    "            return age\n",
    "        except ValueError:\n",
    "            return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process the video and predict age for each frame\n",
    "def process_video(video_path,output_path):\n",
    "    # Load Haar Cascade for face detection\n",
    "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}\")\n",
    "        return\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert frame to grayscale for face detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "        # Predict age for each detected face\n",
    "        for (x, y, w, h) in faces:\n",
    "            face_img = frame[y:y+h, x:x+w]\n",
    "            age_prediction = predict_age_from_image(face_img)\n",
    "            print(f\"Predicted Age: {age_prediction}\")\n",
    "\n",
    "            # Display the resulting frame with age prediction\n",
    "            if age_prediction != \"Error\":\n",
    "                cv2.putText(frame, f\"{age_prediction}\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (144, 238, 144), 2)\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "        cv2.imshow('Age Prediction', frame)\n",
    "\n",
    "        # Break the loop on 'q' key press\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "video_path = 'walk1.mp4'\n",
    "output_path = 'walk1output.mp4'\n",
    "process_video(video_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capture frames from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Predict age from the current frame\n",
    "    age_prediction = predict_age_from_image(frame)\n",
    "    print(f\"Predicted Age: {age_prediction}\")\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.putText(frame, f\"Age: {age_prediction}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "    cv2.imshow('Age Prediction', frame)\n",
    "\n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "image_path = '/Users/satyajeetkadu/Downloads/IMG_2013.JPG'\n",
    "age_prediction = predict_age_from_image(image_path)\n",
    "print(age_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def convert_aac_to_mp3(input_file_path, output_file_path):\n",
    "    # Load the AAC file\n",
    "    audio = AudioSegment.from_file(input_file_path, format=\"aac\")\n",
    "    \n",
    "    # Export as MP3\n",
    "    audio.export(output_file_path, format=\"mp3\")\n",
    "\n",
    "# Define input and output paths\n",
    "input_file = [\"noice_file1.aac\",\"noise1.aac\",\"noise2.aac\"]\n",
    "output_file = [\"noice_file1.mp3\",\"noise1.mp3\",\"noise2.mp3\"]\n",
    "\n",
    "# Convert AAC to MP3\n",
    "for input_file, output_file in zip(input_file, output_file):\n",
    "    convert_aac_to_mp3(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_transcribe_audio(aac_file_path):\n",
    "    \"\"\"\n",
    "    This function takes an AAC audio file, converts it to MP3, and then transcribes the audio using OpenAI's Whisper model.\n",
    "    \n",
    "    Args:\n",
    "    aac_file_path (str): The path to the AAC file.\n",
    "    openai_api_key (str): Your OpenAI API key.\n",
    "    \n",
    "    Returns:\n",
    "    str: The transcription of the audio.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the API key from .env file\n",
    "    load_dotenv()\n",
    "    openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "    # Define the MP3 output path\n",
    "    mp3_file_path = aac_file_path.replace(\".aac\", \".mp3\")\n",
    "    \n",
    "    # Convert AAC to MP3\n",
    "    audio = AudioSegment.from_file(aac_file_path, format=\"aac\")\n",
    "    audio.export(mp3_file_path, format=\"mp3\")\n",
    "\n",
    "    # Initialize OpenAI API\n",
    "    client.api_key = openai_api_key\n",
    "\n",
    "\n",
    "    # Open the MP3 file and transcribe\n",
    "    with open(mp3_file_path, \"rb\") as audio_file:\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\", \n",
    "            file=audio_file\n",
    "        )\n",
    "    \n",
    "    # Clean up the MP3 file after transcription\n",
    "    os.remove(mp3_file_path)\n",
    "    \n",
    "    # Return the transcribed text\n",
    "    return transcription.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_files = [\"noice_file1.aac\",\"noise1.aac\",\"noise2.aac\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each file and print the transcription\n",
    "for input_file in input_files:\n",
    "    text = process_and_transcribe_audio(input_file)\n",
    "    print(f\"Transcription for {input_file}:\")\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import subprocess\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    This function takes an AAC audio file, converts it to MP3 using FFmpeg, and then transcribes the audio using OpenAI's Whisper model.\n",
    "    \n",
    "    Args:\n",
    "    aac_file_path (str): The path to the AAC file.\n",
    "    \n",
    "    Returns:\n",
    "    str: The transcription of the audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_transcribe_audio(aac_file_path):\n",
    "    \"\"\"\n",
    "    This function takes an AAC audio file, converts it to MP3 using FFmpeg, and then transcribes the audio using OpenAI's Whisper model.\n",
    "    \n",
    "    Args:\n",
    "    aac_file_path (str): The path to the AAC file.\n",
    "    \n",
    "    Returns:\n",
    "    str: The transcription of the audio.\n",
    "    \"\"\"\n",
    "    # Load the API key from .env file\n",
    "    load_dotenv()\n",
    "    openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "    \n",
    "    if not openai_api_key:\n",
    "        raise ValueError(\"OpenAI API key not found in the environment variables.\")\n",
    "    \n",
    "    # Define the MP3 output path\n",
    "    mp3_file_path = aac_file_path.replace(\".aac\", \".mp3\")\n",
    "    \n",
    "    # Convert AAC to MP3 using FFmpeg and suppress output\n",
    "    try:\n",
    "        with open(os.devnull, 'w') as devnull:\n",
    "            subprocess.run(['ffmpeg', '-i', aac_file_path, mp3_file_path], stdout=devnull, stderr=devnull, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error occurred while converting {aac_file_path} to MP3: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize OpenAI API\n",
    "    client.api_key = openai_api_key\n",
    "    \n",
    "    # Open the MP3 file and transcribe\n",
    "    with open(mp3_file_path, \"rb\") as audio_file:\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\", \n",
    "            file=audio_file\n",
    "        )\n",
    "    \n",
    "    # Clean up the MP3 file after transcription\n",
    "    os.remove(mp3_file_path)\n",
    "    \n",
    "    # Return the transcribed text\n",
    "    return transcription.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    This function takes an MP3 audio file and transcribes the audio using OpenAI's Whisper model.\n",
    "    \n",
    "    Args:\n",
    "    mp3_file_path (str): The path to the MP3 file.\n",
    "    \n",
    "    Returns:\n",
    "    str: The transcription of the audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def process_and_transcribe_audio(mp3_file_path):\n",
    "    \"\"\"\n",
    "    This function takes an MP3 audio file and transcribes the audio using OpenAI's Whisper model.\n",
    "    \n",
    "    Args:\n",
    "    mp3_file_path (str): The path to the MP3 file.\n",
    "    \n",
    "    Returns:\n",
    "    str: The transcription of the audio.\n",
    "    \"\"\"\n",
    "    # Load the API key from .env file\n",
    "    load_dotenv()\n",
    "    openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "    \n",
    "    if not openai_api_key:\n",
    "        raise ValueError(\"OpenAI API key not found in the environment variables.\")\n",
    "    \n",
    "    # Initialize OpenAI API\n",
    "    client.api_key = openai_api_key\n",
    "    \n",
    "    # Open the MP3 file and transcribe\n",
    "    with open(mp3_file_path, \"rb\") as audio_file:\n",
    "        transcription = client.audio.transcriptions.create(\n",
    "            model=\"whisper-1\", \n",
    "            file=audio_file\n",
    "        )\n",
    "    \n",
    "    # Return the transcribed text\n",
    "    return transcription.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the MP3 files\n",
    "mp3_directory = \"downloaded_mp3s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '/Users/satyajeetkadu/Documents/AudioToText/downloaded_mp3s/trimmed_test2.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_file='noice_file1.aac'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of input MP3 files from the specified directory\n",
    "# input_files = [os.path.join(mp3_directory, f) for f in os.listdir(mp3_directory) if f.endswith('.mp3')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each file and print the transcription\n",
    "text = process_and_transcribe_audio(input_file)\n",
    "print(f\"Transcription for {input_file}:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Different Segments from https://www.youtube.com/watch?v=zDJgG6hcs7c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_boston_1 = '/Users/satyajeetkadu/Documents/AudioToText/downloaded_mp3s/boston_trim1.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each file and print the transcription\n",
    "text = process_and_transcribe_audio(segment_boston_1)\n",
    "print(f\"Transcription for {segment_boston_1}:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_boston_2 = '/Users/satyajeetkadu/Documents/AudioToText/downloaded_mp3s/boston_trim2.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each file and print the transcription\n",
    "text = process_and_transcribe_audio(segment_boston_2)\n",
    "print(f\"Transcription for {segment_boston_2}:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_boston_3 = '/Users/satyajeetkadu/Documents/AudioToText/downloaded_mp3s/boston_trim3.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each file and print the transcription\n",
    "text = process_and_transcribe_audio(segment_boston_3)\n",
    "print(f\"Transcription for {segment_boston_3}:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Different Segments from https://www.youtube.com/watch?v=b6yqknRixWM&t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_woman_1 = '/Users/satyajeetkadu/Documents/AudioToText/downloaded_mp3s/woman_trim1.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each file and print the transcription\n",
    "text = process_and_transcribe_audio(segment_woman_1)\n",
    "print(f\"Transcription for {segment_woman_1}:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_woman_2 = '/Users/satyajeetkadu/Documents/AudioToText/downloaded_mp3s/woman_trim2.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each file and print the transcription\n",
    "text = process_and_transcribe_audio(segment_woman_2)\n",
    "print(f\"Transcription for {segment_woman_2}:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_woman_3 = '/Users/satyajeetkadu/Documents/AudioToText/downloaded_mp3s/woman_trim3.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each file and print the transcription\n",
    "text = process_and_transcribe_audio(segment_woman_3)\n",
    "print(f\"Transcription for {segment_woman_3}:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_woman_4 = '/Users/satyajeetkadu/Documents/AudioToText/downloaded_mp3s/woman_trim4.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each file and print the transcription\n",
    "text = process_and_transcribe_audio(segment_woman_4)\n",
    "print(f\"Transcription for {segment_woman_4}:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing Different Segments from https://youtu.be/Uo4ZcCEtBlk?si=P-kXBbm--VrFaJ5K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_cocaine_1 = '/Users/satyajeetkadu/Documents/AudioToText/downloaded_mp3s/cocain_trim1.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each file and print the transcription\n",
    "text = process_and_transcribe_audio(segment_cocaine_1)\n",
    "print(f\"Transcription for {segment_cocaine_1}:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_cocaine_2 = '/Users/satyajeetkadu/Documents/AudioToText/downloaded_mp3s/cocain_trim2.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each file and print the transcription\n",
    "text = process_and_transcribe_audio(segment_cocaine_2)\n",
    "print(f\"Transcription for {segment_cocaine_2}:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_cocaine_3 = '/Users/satyajeetkadu/Documents/AudioToText/downloaded_mp3s/cocain_trim3.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each file and print the transcription\n",
    "text = process_and_transcribe_audio(segment_cocaine_3)\n",
    "print(f\"Transcription for {segment_cocaine_3}:\")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing API BELOW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "client = OpenAI()\n",
    "# defaults to getting the key using os.environ.get(\"OPENAI_API_KEY\")\n",
    "# if you saved the key under a different environment variable name, you can do something like:\n",
    "client = OpenAI(\n",
    "  api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pytube ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytube\n",
    "import ffmpeg\n",
    "import os\n",
    "import ssl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Download a YouTube video and save it to the specified output path.\n",
    "    \n",
    "    Args:\n",
    "    youtube_url (str): The URL of the YouTube video.\n",
    "    output_path (str): The path to save the downloaded video file.\n",
    "    \n",
    "    Returns:\n",
    "    str: The path to the downloaded video file and the title of the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_youtube_video(youtube_url, output_path):\n",
    "    \"\"\"\n",
    "    Download a YouTube video and save it to the specified output path.\n",
    "    \n",
    "    Args:\n",
    "    youtube_url (str): The URL of the YouTube video.\n",
    "    output_path (str): The path to save the downloaded video file.\n",
    "    \n",
    "    Returns:\n",
    "    str: The path to the downloaded video file and the title of the video.\n",
    "    \"\"\"\n",
    "    # Download the YouTube video\n",
    "\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "    yt = pytube.YouTube(youtube_url)\n",
    "    stream = yt.streams.filter(only_audio=True).first()\n",
    "    video_title = yt.title\n",
    "    sanitized_title = \"\".join(c if c.isalnum() or c in (' ', '-', '_') else '_' for c in video_title)\n",
    "    video_file_path = os.path.join(output_path, f\"{sanitized_title}.mp4\")\n",
    "    stream.download(output_path=output_path, filename=f\"{sanitized_title}.mp4\")\n",
    "    return video_file_path, sanitized_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Convert a video file to MP3 using FFmpeg.\n",
    "    \n",
    "    Args:\n",
    "    video_file_path (str): The path to the video file.\n",
    "    mp3_file_path (str): The path to save the converted MP3 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_to_mp3(video_file_path, mp3_file_path):\n",
    "    \"\"\"\n",
    "    Convert a video file to MP3 using FFmpeg.\n",
    "    \n",
    "    Args:\n",
    "    video_file_path (str): The path to the video file.\n",
    "    mp3_file_path (str): The path to save the converted MP3 file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ffmpeg.input(video_file_path).output(mp3_file_path).run(overwrite_output=True)\n",
    "    except ffmpeg.Error as e:\n",
    "        print(f\"Error occurred while converting {video_file_path} to MP3: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Download a YouTube video, convert it to MP3, and save it to the specified output path.\n",
    "    \n",
    "    Args:\n",
    "    youtube_url (str): The URL of the YouTube video.\n",
    "    output_path (str): The directory to save the MP3 file.\n",
    "    \n",
    "    Returns:\n",
    "    str: The path to the converted MP3 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_convert(youtube_url, output_path):\n",
    "    \"\"\"\n",
    "    Download a YouTube video, convert it to MP3, and save it to the specified output path.\n",
    "    \n",
    "    Args:\n",
    "    youtube_url (str): The URL of the YouTube video.\n",
    "    output_path (str): The directory to save the MP3 file.\n",
    "    \n",
    "    Returns:\n",
    "    str: The path to the converted MP3 file.\n",
    "    \"\"\"\n",
    "    # Download the video\n",
    "    video_file_path, video_title = download_youtube_video(youtube_url, output_path)\n",
    "    \n",
    "    # Define the MP3 file path\n",
    "    mp3_file_path = os.path.join(output_path, f\"{video_title}.mp3\")\n",
    "    \n",
    "    # Convert the video to MP3\n",
    "    convert_to_mp3(video_file_path, mp3_file_path)\n",
    "    \n",
    "    # Remove the original video file\n",
    "    os.remove(video_file_path)\n",
    "    \n",
    "    return mp3_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of YouTube video URLs\n",
    "youtube_urls = [\n",
    "    \"https://www.youtube.com/watch?v=qTGPCuY1S64\",\n",
    "    \"https://www.youtube.com/watch?v=Vlxy-NUes14\",\n",
    "    \"https://www.youtube.com/watch?v=U0JvPJiNUEo\",\n",
    "    \"https://www.youtube.com/watch?v=uFDx_jlV1mY\",\n",
    "    \"https://www.youtube.com/watch?v=CT5GcN1HCn4\",\n",
    "    \"https://www.youtube.com/watch?v=OqfHTxmrJeo\",\n",
    "    \"https://www.youtube.com/watch?v=b6yqknRixWM\",\n",
    "    \"https://www.youtube.com/watch?v=nM3W2p0gx7A\",\n",
    "    \"https://www.youtube.com/watch?v=D3Qn9jO5ku0\",\n",
    "    \"https://www.youtube.com/watch?v=3hd1OupgUBo\",\n",
    "    \"https://www.youtube.com/watch?v=zDJgG6hcs7c\",\n",
    "    \"https://www.youtube.com/watch?v=H6j_ZOlk_vo\",\n",
    "    \"https://www.youtube.com/watch?v=-_hc1QfVMOI\",\n",
    "    \"https://www.youtube.com/watch?v=4UE_aRtv1ic\",\n",
    "    \"https://www.youtube.com/watch?v=QFTxtZXLJs0\",\n",
    "    \"https://www.youtube.com/watch?v=7EgfGq2unjY\",\n",
    "    \"https://www.youtube.com/watch?v=bvYQHBW7hNs\",\n",
    "    \"https://www.youtube.com/watch?v=EZb6kiCif9g\",\n",
    "    \"https://www.youtube.com/watch?v=e3g2o0eTm_E\",\n",
    "    \"https://www.youtube.com/watch?v=2aYy9cJoRv4\",\n",
    "    \"https://www.youtube.com/watch?v=gYWhwure9X8\",\n",
    "    \"https://www.youtube.com/watch?v=0OvufDpsz3o\",\n",
    "    \"https://www.youtube.com/watch?v=Uo4ZcCEtBlk\",\n",
    "    \"https://www.youtube.com/watch?v=nnOtyRa9uyA\",\n",
    "    \"https://www.youtube.com/watch?v=VBtseYkRwdU\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory to save the MP3 files\n",
    "output_directory = \"downloaded_mp3s\"\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and convert each YouTube video to MP3\n",
    "for url in youtube_urls:\n",
    "    mp3_file_path = download_and_convert(url, output_directory)\n",
    "    print(f\"Downloaded and converted to MP3: {mp3_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I have given codes for two scenarios:-\n",
    "1) Converting An AAC file to MP3 using FFMPEG and then using Open AI Whisper model to transcribe text from speech\n",
    "2) Downloading YT videos and converting them to mp3 and then using Open AI Whisper model to transcribe text from speech\n",
    "\n",
    "Conclusions:-\n",
    "\n",
    "1) Faced issues converting YT videos which were very long, most of them were around 30-40 minutes, hence i tried trimming some segments and transcribing the speech, which gave highly accurate results\n",
    "2) To solve this issue, we can run the code on servers such as AWS, Google Cloud Platform ,Azure etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
